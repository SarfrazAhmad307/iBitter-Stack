{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12929533,"sourceType":"datasetVersion","datasetId":6484972,"isSourceIdPinned":false}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### packages required \n!pip install fair-esm\n!pip install torch\n!pip install tensorflow\n!pip install sklearn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:50:06.740612Z","iopub.execute_input":"2025-09-01T09:50:06.740847Z","iopub.status.idle":"2025-09-01T09:50:19.220080Z","shell.execute_reply.started":"2025-09-01T09:50:06.740827Z","shell.execute_reply":"2025-09-01T09:50:19.219048Z"}},"outputs":[{"name":"stdout","text":"Collecting fair-esm\n  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\nDownloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fair-esm\nSuccessfully installed fair-esm-2.0.0\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\nRequirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\nCollecting sklearn\n  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import sklearn\nprint(sklearn.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:50:19.221204Z","iopub.execute_input":"2025-09-01T09:50:19.221540Z","iopub.status.idle":"2025-09-01T09:50:19.637308Z","shell.execute_reply.started":"2025-09-01T09:50:19.221509Z","shell.execute_reply":"2025-09-01T09:50:19.636554Z"}},"outputs":[{"name":"stdout","text":"1.2.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Ensemble Experiment ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport math\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, ExtraTreesRegressor\nfrom sklearn.model_selection import LeaveOneOut, cross_validate, cross_val_score, StratifiedShuffleSplit, train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV, LeaveOneOut\nfrom sklearn.metrics import confusion_matrix\nimport math\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier  # Import Decision Tree\nfrom sklearn.model_selection import GridSearchCV, LeaveOneOut  # Model selection tools\n\n\nimport warnings\n\n# Suppress all warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:50:19.638225Z","iopub.execute_input":"2025-09-01T09:50:19.638687Z","iopub.status.idle":"2025-09-01T09:50:20.374189Z","shell.execute_reply.started":"2025-09-01T09:50:19.638653Z","shell.execute_reply":"2025-09-01T09:50:20.373276Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Base Learner","metadata":{}},{"cell_type":"code","source":"def SVM(X,Y,x,y):\n    param_grid = {\n        'C': [0.01, 0.1, 1, 10, 100],  # Regularization parameter\n        'kernel': ['linear', 'rbf', 'sigmoid'],  # Removed 'precomputed' kernel\n    }\n    svm=SVC(random_state=42, probability=True)\n    svm_cv = GridSearchCV(svm, param_grid, scoring='accuracy', cv=KFold(10), n_jobs=4)\n    \n    # fitting the model for grid search\n    svm_cv.fit(X,Y)\n    svm=svm_cv.best_estimator_\n    \n    print('\\n Test Results SVM\\n')\n    y_p=svm.predict(x)\n    \n    TP, FP, FN, TN = confusion_matrix(y, y_p).ravel()\n    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n    \n    print('Best accuracy and parameters are: ', svm_cv.best_score_, svm_cv.best_params_)\n    accuracy = accuracy_score(y, y_p)\n    print(\"Accuracy:\", accuracy)\n    print('MCC:', MCC)\n    \n    return svm, MCC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:53:57.734972Z","iopub.execute_input":"2025-09-01T09:53:57.735285Z","iopub.status.idle":"2025-09-01T09:53:57.741517Z","shell.execute_reply.started":"2025-09-01T09:53:57.735264Z","shell.execute_reply":"2025-09-01T09:53:57.740515Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def Tree(X,Y,x,y):\n    #create new a tree model\n    DT=DecisionTreeClassifier(random_state=42)\n    param_grid = {'max_depth':range(2,20),\n                'criterion':['gini', 'entropy']}\n    tree_cv = GridSearchCV(DT, param_grid, scoring='accuracy', cv=KFold(10), n_jobs=4)\n    tree_cv.fit(X, Y)\n    tree=tree_cv.best_estimator_\n    \n    print('\\n Test Results Decision Tree\\n')\n    y_p=tree.predict(x)\n    \n    TP, FP, FN, TN = confusion_matrix(y, y_p).ravel()\n    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n    print('Best accuracy and parameters are: ', tree_cv.best_score_, tree_cv.best_params_)\n    accuracy = accuracy_score(y, y_p)\n    print(\"Accuracy:\", accuracy)\n    print('MCC:', MCC)\n    \n    return tree, MCC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:53:58.656007Z","iopub.execute_input":"2025-09-01T09:53:58.656306Z","iopub.status.idle":"2025-09-01T09:53:58.662064Z","shell.execute_reply.started":"2025-09-01T09:53:58.656283Z","shell.execute_reply":"2025-09-01T09:53:58.661224Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def NaiveBayes(X, Y, x, y):\n    # Create a Naive Bayes model\n    NB = GaussianNB()\n    \n    # Define hyperparameter grid (only 'var_smoothing' for GaussianNB)\n    param_grid = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]}\n\n    # GridSearchCV with Leave-One-Out Cross-Validation\n    nb_cv = GridSearchCV(NB, param_grid, scoring='accuracy', cv=KFold(10), n_jobs=4)\n    nb_cv.fit(X, Y)\n    nb=nb_cv.best_estimator_\n    \n    print('\\n Test Results Naive Bayes\\n')\n    y_p=nb.predict(x)\n    \n    TP, FP, FN, TN = confusion_matrix(y, y_p).ravel()\n    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n    print('Best accuracy and parameters are: ', nb_cv.best_score_, nb_cv.best_params_)\n    accuracy = accuracy_score(y, y_p)\n    print(\"Accuracy:\", accuracy)\n    print('MCC:', MCC)\n    \n    return nb, MCC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:54:01.915881Z","iopub.execute_input":"2025-09-01T09:54:01.916348Z","iopub.status.idle":"2025-09-01T09:54:01.921890Z","shell.execute_reply.started":"2025-09-01T09:54:01.916311Z","shell.execute_reply":"2025-09-01T09:54:01.921098Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def KNN(X,Y,x,y):\n    #create new a knn model\n    knn = KNeighborsClassifier()\n    #create a dictionary of all values we want to test for n_neighbors\n    param_grid = {'n_neighbors': np.arange(1, 10),\n                'metric': ['minkowski', 'euclidean', 'manhattan']}\n    #use gridsearch to test all values for n_neighbors\n    knn_cv = GridSearchCV(knn, param_grid, scoring='accuracy', cv=KFold(10), n_jobs=4)\n    #fit model to data\n    knn_cv.fit(X, Y)\n    knn = knn_cv.best_estimator_\n    \n    print('\\n Test Results KNN\\n')\n    y_p=knn.predict(x)\n    \n    TP, FP, FN, TN = confusion_matrix(y, y_p).ravel()\n    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n    print ('Best accuracy and parameters are: ', knn_cv.best_score_, knn_cv.best_params_)\n    accuracy = accuracy_score(y, y_p)\n    print(\"Accuracy:\", accuracy)\n    print('MCC:', MCC)\n    return knn, MCC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:54:04.107102Z","iopub.execute_input":"2025-09-01T09:54:04.107383Z","iopub.status.idle":"2025-09-01T09:54:04.112956Z","shell.execute_reply.started":"2025-09-01T09:54:04.107363Z","shell.execute_reply":"2025-09-01T09:54:04.111991Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def LRegression(X,Y,x,y):\n    #create new a tree model\n    LR=LogisticRegression(random_state=42, max_iter=1500)\n    param_grid = {'penalty':['l2', None]}\n    \n    lr_cv = GridSearchCV(LR, param_grid, scoring='accuracy', cv=KFold(10), n_jobs=4)\n    lr_cv.fit(X, Y)\n    lr=lr_cv.best_estimator_\n    \n    print('\\n Test Results LR\\n')\n    y_p=lr.predict(x)\n    \n    TP, FP, FN, TN = confusion_matrix(y, y_p).ravel()\n    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n    print('Best accuracy and parameters are: ', lr_cv.best_score_, lr_cv.best_params_)\n    accuracy = accuracy_score(y, y_p)\n    print(\"Accuracy:\", accuracy)\n    print('MCC:', MCC)\n    \n    return lr, MCC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:54:06.358763Z","iopub.execute_input":"2025-09-01T09:54:06.359064Z","iopub.status.idle":"2025-09-01T09:54:06.364668Z","shell.execute_reply.started":"2025-09-01T09:54:06.359042Z","shell.execute_reply":"2025-09-01T09:54:06.363839Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def RandomForest(X,Y,x,y):\n    # Number of trees in random forest\n    max_depth=range(2,20)\n    # Number of features to consider at every split\n    max_features = ['auto', 'sqrt', 'log2']\n    # Maximum number of levels in tree\n    criterion = ['gini', 'entropy']\n    \n    random_grid = {'max_depth': max_depth,\n                'criterion': criterion,\n                'max_features': max_features}\n    \n    rf = RandomForestClassifier(random_state=42)\n    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n                                cv=KFold(10), random_state=42, n_jobs = 4)\n    rf_random.fit(X, Y)\n    rf = rf_random.best_estimator_\n    \n    print('\\n Test Results RF\\n')\n    y_p=rf.predict(x)\n    \n    TP, FP, FN, TN = confusion_matrix(y, y_p).ravel()\n    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n    print ('Best accuracy and parameters are: ', rf_random.best_score_, rf_random.best_params_)\n    accuracy = accuracy_score(y, y_p)\n    print(\"Accuracy:\", accuracy)\n    print('MCC:', MCC)\n    \n    return rf, MCC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:54:10.884845Z","iopub.execute_input":"2025-09-01T09:54:10.885133Z","iopub.status.idle":"2025-09-01T09:54:10.890959Z","shell.execute_reply.started":"2025-09-01T09:54:10.885112Z","shell.execute_reply":"2025-09-01T09:54:10.890005Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def ADABoost(X,Y,x,y):\n    #create new a tree model\n    Ada = AdaBoostClassifier(DecisionTreeClassifier(random_state=42), random_state=42)\n    param_grid = {'estimator__max_depth' : [1, 2, 3, 4, 5],\n                'estimator__criterion' : ['gini', 'entropy'],\n                'estimator__splitter' :   ['best', 'random']}\n    ada_cv = GridSearchCV(Ada, param_grid, cv=KFold(10), scoring = 'accuracy', n_jobs=4)\n    ada_cv.fit(X,Y)\n    ada=ada_cv.best_estimator_\n    \n    print('\\n Test Results ADABoost\\n')\n    y_p=ada.predict(x)\n    \n    TP, FP, FN, TN = confusion_matrix(y, y_p).ravel()\n    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n    print('Best accuracy and parameters are: ', ada_cv.best_score_, ada_cv.best_params_)\n    accuracy = accuracy_score(y, y_p)\n    print(\"Accuracy:\", accuracy)\n    print('MCC:', MCC)\n    \n    return ada, MCC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:54:11.662301Z","iopub.execute_input":"2025-09-01T09:54:11.662595Z","iopub.status.idle":"2025-09-01T09:54:11.668464Z","shell.execute_reply.started":"2025-09-01T09:54:11.662574Z","shell.execute_reply":"2025-09-01T09:54:11.667417Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def MLPClassify(X,Y,x,y):\n    #create new a tree model\n    MLP=MLPClassifier(random_state=42, max_iter=1000)\n    param_grid = {\n      'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],  # Different sizes of hidden layers\n      'activation': ['relu', 'tanh', 'logistic'],  # Activation functions\n      'solver': ['adam', 'sgd'],  # Optimization algorithms\n      'alpha': [0.0001, 0.001, 0.01],  # L2 regularization parameter\n      'learning_rate': ['constant', 'adaptive']  # Learning rate schedule\n    }\n    \n    mlp_cv = GridSearchCV(MLP, param_grid, scoring='accuracy', cv=KFold(10), n_jobs=4)\n    mlp_cv.fit(X, Y)\n    mlp=mlp_cv.best_estimator_\n    \n    print('\\n Test Results MLP\\n')\n    y_p=mlp.predict(x)\n    \n    TP, FP, FN, TN = confusion_matrix(y, y_p).ravel()\n    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n    print('Best accuracy and parameters are: ', mlp_cv.best_score_, mlp_cv.best_params_)\n    accuracy = accuracy_score(y, y_p)\n    print(\"Accuracy:\", accuracy)\n    print('MCC:', MCC)\n    \n    return mlp, MCC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:54:15.225278Z","iopub.execute_input":"2025-09-01T09:54:15.225601Z","iopub.status.idle":"2025-09-01T09:54:15.231421Z","shell.execute_reply.started":"2025-09-01T09:54:15.225575Z","shell.execute_reply":"2025-09-01T09:54:15.230703Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### ESM Embeddings","metadata":{}},{"cell_type":"code","source":"def esm_embeddings(peptide_sequence_list):\n  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long, \n  #         or you have too many sequences for transformation in a single converting, \n  #         you conputer might automatically kill the job.\n  import torch\n  import esm\n  import collections\n  # load the model\n  # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.\n  model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n  batch_converter = alphabet.get_batch_converter()\n  model.eval()  # disables dropout for deterministic results\n\n  # load the peptide sequence list into the bach_converter\n  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n  ## batch tokens are the embedding results of the whole data set\n\n  # Extract per-residue representations (on CPU)\n  with torch.no_grad():\n      # Here we export the last layer of the EMS model output as the representation of the peptides\n      # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n      results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n  token_representations = results[\"representations\"][6]\n\n  # Generate per-sequence representations via averaging\n  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n  sequence_representations = []\n  for i, tokens_len in enumerate(batch_lens):\n      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n  # save dataset\n  # sequence_representations is a list and each element is a tensor\n  embeddings_results = collections.defaultdict(list)\n  for i in range(len(sequence_representations)):\n      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n      each_seq_rep = sequence_representations[i].tolist()\n      for each_element in each_seq_rep:\n          embeddings_results[i].append(each_element)\n  embeddings_results = pd.DataFrame(embeddings_results).T\n  return embeddings_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:54:27.102808Z","iopub.execute_input":"2025-09-01T09:54:27.103208Z","iopub.status.idle":"2025-09-01T09:54:27.111141Z","shell.execute_reply.started":"2025-09-01T09:54:27.103175Z","shell.execute_reply":"2025-09-01T09:54:27.110108Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# training dataset loading\ntrain = pd.read_excel('/kaggle/input/bitter-esm/bitter_train_filtered_80.xlsx',na_filter = False) # take care the NA sequence problem\nsequence_list = train['sequence']\npeptide_sequence_list = []\nfor seq in sequence_list:\n    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n    tuple_sequence = tuple(format_seq)\n    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n\n# employ ESM model for converting and save the converted data in csv format\nembeddings_results = esm_embeddings(peptide_sequence_list)\nembeddings_results.to_csv('/kaggle/working/bitter_train_esm.csv')\n\n# loading the y dataset for model development \ny_train = train['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:54:42.687913Z","iopub.execute_input":"2025-09-01T09:54:42.688198Z","iopub.status.idle":"2025-09-01T09:54:53.482698Z","shell.execute_reply.started":"2025-09-01T09:54:42.688178Z","shell.execute_reply":"2025-09-01T09:54:53.482050Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D.pt\nDownloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t6_8M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D-contact-regression.pt\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# test dataset loading\ntest = pd.read_excel('/kaggle/input/bitter-esm/bitter_test_filtered_80.xlsx',na_filter = False)\nsequence_list = test['sequence'] \npeptide_sequence_list = []\nfor seq in sequence_list:\n    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n    tuple_sequence = tuple(format_seq)\n    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n\n# employ ESM model for converting and save the converted data in csv format\nembeddings_results = esm_embeddings(peptide_sequence_list)\nembeddings_results.to_csv('/kaggle/working/bitter_test_esm.csv')\n\n# loading the y dataset for model development \ny_test = test['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:55:05.347410Z","iopub.execute_input":"2025-09-01T09:55:05.347700Z","iopub.status.idle":"2025-09-01T09:55:05.896968Z","shell.execute_reply.started":"2025-09-01T09:55:05.347679Z","shell.execute_reply":"2025-09-01T09:55:05.896259Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def ESM():\n    # assign the dataset \n    train_path = '/kaggle/working/bitter_train_esm.csv'\n    train_data = pd.read_csv(train_path, header=0, index_col = 0, delimiter=',')\n    \n    test_path = '/kaggle/working/bitter_test_esm.csv'\n    test_data = pd.read_csv(test_path,header=0, index_col = 0,delimiter=',')\n    \n    X_train = np.array(train_data)\n    X_test = np.array(test_data)\n    \n    # normalize the X data range\n    from sklearn.preprocessing import MinMaxScaler\n    scaler = MinMaxScaler()\n    scaler.fit(X_train)\n    X_train = scaler.transform(X_train) # normalize X to 0-1 range \n    X_test = scaler.transform(X_test)\n    return X_train, X_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:55:14.697077Z","iopub.execute_input":"2025-09-01T09:55:14.697373Z","iopub.status.idle":"2025-09-01T09:55:14.702139Z","shell.execute_reply.started":"2025-09-01T09:55:14.697350Z","shell.execute_reply":"2025-09-01T09:55:14.701225Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"X_train, X_test = ESM()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:55:19.972200Z","iopub.execute_input":"2025-09-01T09:55:19.972504Z","iopub.status.idle":"2025-09-01T09:55:20.035708Z","shell.execute_reply.started":"2025-09-01T09:55:19.972481Z","shell.execute_reply":"2025-09-01T09:55:20.034822Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:55:20.931920Z","iopub.execute_input":"2025-09-01T09:55:20.932210Z","iopub.status.idle":"2025-09-01T09:55:20.937777Z","shell.execute_reply.started":"2025-09-01T09:55:20.932189Z","shell.execute_reply":"2025-09-01T09:55:20.937064Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"((428, 320), (86, 320))"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"svm, mcc = SVM(X_train, y_train, X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:55:41.748886Z","iopub.execute_input":"2025-09-01T09:55:41.749174Z","iopub.status.idle":"2025-09-01T09:55:51.078985Z","shell.execute_reply.started":"2025-09-01T09:55:41.749152Z","shell.execute_reply":"2025-09-01T09:55:51.078112Z"}},"outputs":[{"name":"stdout","text":"\n Test Results SVM\n\nBest accuracy and parameters are:  0.83421926910299 {'C': 10, 'kernel': 'rbf'}\nAccuracy: 0.872093023255814\nMCC: 0.7441107248077677\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# train models and store MCCs in a dictionary as follow: {model_name: MCC}\nmodels = {\n            'ESM_SVM' : SVM(X_train, y_train, X_test, y_test),\n            'ESM_DT' : Tree(X_train, y_train, X_test, y_test),\n            'ESM_NB' : NaiveBayes(X_train, y_train, X_test, y_test),\n            'ESM_KNN': KNN(X_train, y_train, X_test, y_test),\n            'ESM_LR': LRegression(X_train, y_train, X_test, y_test),\n            'ESM_RF': RandomForest(X_train, y_train, X_test, y_test),\n            'ESM_ADA': ADABoost(X_train, y_train, X_test, y_test),\n            'ESM_MLP': MLPClassify(X_train, y_train, X_test, y_test)\n         }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T09:55:58.550937Z","iopub.execute_input":"2025-09-01T09:55:58.551238Z","iopub.status.idle":"2025-09-01T10:13:26.283696Z","shell.execute_reply.started":"2025-09-01T09:55:58.551213Z","shell.execute_reply":"2025-09-01T10:13:26.282801Z"}},"outputs":[{"name":"stdout","text":"\n Test Results SVM\n\nBest accuracy and parameters are:  0.83421926910299 {'C': 10, 'kernel': 'rbf'}\nAccuracy: 0.872093023255814\nMCC: 0.7441107248077677\n\n Test Results Decision Tree\n\nBest accuracy and parameters are:  0.7100221483942415 {'criterion': 'gini', 'max_depth': 6}\nAccuracy: 0.8372093023255814\nMCC: 0.6746219776463768\n\n Test Results Naive Bayes\n\nBest accuracy and parameters are:  0.7358250276854928 {'var_smoothing': 0.01}\nAccuracy: 0.8372093023255814\nMCC: 0.6819317770742027\n\n Test Results KNN\n\nBest accuracy and parameters are:  0.794296788482835 {'metric': 'manhattan', 'n_neighbors': 7}\nAccuracy: 0.8488372093023255\nMCC: 0.6997023700521369\n\n Test Results LR\n\nBest accuracy and parameters are:  0.8059246954595791 {'penalty': 'l2'}\nAccuracy: 0.872093023255814\nMCC: 0.7441107248077677\n\n Test Results RF\n\nBest accuracy and parameters are:  0.8085271317829456 {'max_features': 'log2', 'max_depth': 9, 'criterion': 'entropy'}\nAccuracy: 0.8837209302325582\nMCC: 0.7711514889173213\n\n Test Results ADABoost\n\nBest accuracy and parameters are:  0.7966777408637873 {'estimator__criterion': 'gini', 'estimator__max_depth': 5, 'estimator__splitter': 'best'}\nAccuracy: 0.8604651162790697\nMCC: 0.721259831406496\n\n Test Results MLP\n\nBest accuracy and parameters are:  0.8339977851605758 {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\nAccuracy: 0.9069767441860465\nMCC: 0.8177893426774406\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"### AAE","metadata":{}},{"cell_type":"code","source":"letters = list(\"ACDEFGHIKLMNPQRSTVWY\")\n\n# replace any character from seqeunce which is not in letters to -\ndef replace(seq):\n    return re.sub('[^' + ''.join(letters) + ']', '-', seq)\n\ntrain['sequence'] = train['sequence'].apply(replace)\ntest['sequence'] = test['sequence'].apply(replace)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:13:26.284791Z","iopub.execute_input":"2025-09-01T10:13:26.285120Z","iopub.status.idle":"2025-09-01T10:13:26.291612Z","shell.execute_reply.started":"2025-09-01T10:13:26.285096Z","shell.execute_reply":"2025-09-01T10:13:26.290817Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# AAE\ndef AAE_1(fastas):\n    length = float(len(fastas))\n    amino_acids = dict.fromkeys(letters, 0)\n    encodings = []\n    for AA in amino_acids:\n        hits = [a.start() for a in list(re.finditer(AA, fastas))]\n        p_prev = 0\n        p_next = 1\n        sum = 0\n        while p_next < len(hits):\n            distance = (hits[p_next] - hits[p_prev]) / length\n            sum += distance * math.log(distance, 2)\n            p_prev = p_next\n            p_next += 1\n        amino_acids[AA] = -sum\n        encodings.append(amino_acids[AA])\n    return encodings\n\ndef AAE(seq):\n    encodings = []\n    for fastas in seq:\n        # Extracting sub-sequences\n        fastas_NT5 = \"%s\" % fastas[:5]\n        fastas_CT5 = \"%s\" % fastas[-5:]\n        # Full sequence encoding\n        encodings_full = AAE_1(fastas)\n        # Sub-sequence encoding\n        encodings_CT5 = AAE_1(fastas_CT5)\n        encodings_NT5 = AAE_1(fastas_NT5)\n        # Combine encodings\n        encodings.append(encodings_full + encodings_NT5 + encodings_CT5)\n    return encodings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:13:26.293149Z","iopub.execute_input":"2025-09-01T10:13:26.293400Z","iopub.status.idle":"2025-09-01T10:13:26.307268Z","shell.execute_reply.started":"2025-09-01T10:13:26.293379Z","shell.execute_reply":"2025-09-01T10:13:26.306517Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Compute encodings\ntrain_encodings_result = AAE(train['sequence'].tolist())\ntest_encodings_result = AAE(test['sequence'].tolist())\n\nX_train = pd.DataFrame(train_encodings_result)\nX_test = pd.DataFrame(test_encodings_result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:13:26.308575Z","iopub.execute_input":"2025-09-01T10:13:26.308841Z","iopub.status.idle":"2025-09-01T10:13:26.374965Z","shell.execute_reply.started":"2025-09-01T10:13:26.308817Z","shell.execute_reply":"2025-09-01T10:13:26.374117Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:13:26.375697Z","iopub.execute_input":"2025-09-01T10:13:26.375943Z","iopub.status.idle":"2025-09-01T10:13:26.381050Z","shell.execute_reply.started":"2025-09-01T10:13:26.375925Z","shell.execute_reply":"2025-09-01T10:13:26.380274Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"((428, 60), (86, 60))"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# train models and store MCCs in a dictionary as follow: {model_name: MCC}\nmodels.update(\n    {\n        'AAE_SVM' : SVM(X_train, y_train, X_test, y_test),\n        'AAE_DT' : Tree(X_train, y_train, X_test, y_test),\n        'AAE_NB' : NaiveBayes(X_train, y_train, X_test, y_test),\n        'AAE_KNN': KNN(X_train, y_train, X_test, y_test),\n        'AAE_LR': LRegression(X_train, y_train, X_test, y_test),\n        'AAE_RF': RandomForest(X_train, y_train, X_test, y_test),\n        'AAE_ADA': ADABoost(X_train, y_train, X_test, y_test),\n        'AAE_MLP': MLPClassify(X_train, y_train, X_test, y_test)\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:13:26.381880Z","iopub.execute_input":"2025-09-01T10:13:26.382159Z","iopub.status.idle":"2025-09-01T10:19:25.296001Z","shell.execute_reply.started":"2025-09-01T10:13:26.382131Z","shell.execute_reply":"2025-09-01T10:19:25.295165Z"}},"outputs":[{"name":"stdout","text":"\n Test Results SVM\n\nBest accuracy and parameters are:  0.6144518272425249 {'C': 1, 'kernel': 'rbf'}\nAccuracy: 0.6976744186046512\nMCC: 0.44015540360100736\n\n Test Results Decision Tree\n\nBest accuracy and parameters are:  0.6215393133997785 {'criterion': 'gini', 'max_depth': 16}\nAccuracy: 0.6511627906976745\nMCC: 0.3697869984767234\n\n Test Results Naive Bayes\n\nBest accuracy and parameters are:  0.5983388704318936 {'var_smoothing': 1e-05}\nAccuracy: 0.686046511627907\nMCC: 0.4193309519544422\n\n Test Results KNN\n\nBest accuracy and parameters are:  0.5957918050941307 {'metric': 'manhattan', 'n_neighbors': 1}\nAccuracy: 0.6395348837209303\nMCC: 0.3478516235216784\n\n Test Results LR\n\nBest accuracy and parameters are:  0.6028792912513843 {'penalty': 'l2'}\nAccuracy: 0.6744186046511628\nMCC: 0.3982469291220737\n\n Test Results RF\n\nBest accuracy and parameters are:  0.6237541528239203 {'max_features': 'sqrt', 'max_depth': 5, 'criterion': 'gini'}\nAccuracy: 0.6627906976744186\nMCC: 0.3912213018462842\n\n Test Results ADABoost\n\nBest accuracy and parameters are:  0.6238095238095238 {'estimator__criterion': 'gini', 'estimator__max_depth': 1, 'estimator__splitter': 'random'}\nAccuracy: 0.6627906976744186\nMCC: 0.3912213018462842\n\n Test Results MLP\n\nBest accuracy and parameters are:  0.6122923588039867 {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\nAccuracy: 0.6744186046511628\nMCC: 0.3982469291220737\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"### AAI","metadata":{}},{"cell_type":"code","source":"def AAI_1(fastas):\n    encodings = []\n    fileAAindex1 = open(R\"/kaggle/input/bitter-esm/AAindex_1.txt\")\n    fileAAindex2 = open(R\"/kaggle/input/bitter-esm/AAindex_2.txt\")\n    records1 = fileAAindex1.readlines()[1:]\n    records2 = fileAAindex2.readlines()[1:]\n    AAindex1 = []\n    AAindex2 = []\n    for i in records1:\n        AAindex1.append(i.rstrip().split()[1:] if i.rstrip() != \"\" else None)\n    for i in records2:\n        AAindex2.append(i.rstrip().split()[1:] if i.rstrip() != \"\" else None)\n    index = {}\n    for i in range(len(letters)):\n        index[letters[i]] = i\n    fastas_len = len(fastas)\n    for i in range(len(AAindex1)):\n        total = 0\n        for j in range(fastas_len):\n            temp = AAindex1[i][index[fastas[j]]]\n            total = total + float(temp)\n        encodings.append(total / fastas_len)\n    for i in range(len(AAindex2)):\n        total = 0\n        for j in range(fastas_len):\n            temp = AAindex2[i][index[fastas[j]]]\n            total = total + float(temp)\n        encodings.append(total)\n    return encodings\n\n\ndef AAI(seqs):\n    encodings = []\n    for fastas in seqs:\n        fastas_NT5 = \"%s\" % fastas[:5]\n        fastas_CT5 = \"%s\" % fastas[-5:]\n\n        encodings_full = AAI_1(fastas)\n        encodings_CT5 = AAI_1(fastas_CT5)\n        encodings_NT5 = AAI_1(fastas_NT5)\n        encodings.append(encodings_full + encodings_NT5 + encodings_CT5)\n    return encodings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:19:25.296782Z","iopub.execute_input":"2025-09-01T10:19:25.297019Z","iopub.status.idle":"2025-09-01T10:19:25.304982Z","shell.execute_reply.started":"2025-09-01T10:19:25.297000Z","shell.execute_reply":"2025-09-01T10:19:25.304327Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Compute encodings\ntrain_encodings_result = AAI(train['sequence'].tolist())\ntest_encodings_result = AAI(test['sequence'].tolist())\n\nX_train = pd.DataFrame(train_encodings_result)\nX_test = pd.DataFrame(test_encodings_result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:19:25.307359Z","iopub.execute_input":"2025-09-01T10:19:25.307555Z","iopub.status.idle":"2025-09-01T10:19:26.707245Z","shell.execute_reply.started":"2025-09-01T10:19:25.307539Z","shell.execute_reply":"2025-09-01T10:19:26.706352Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:19:26.708798Z","iopub.execute_input":"2025-09-01T10:19:26.709028Z","iopub.status.idle":"2025-09-01T10:19:26.713749Z","shell.execute_reply.started":"2025-09-01T10:19:26.709010Z","shell.execute_reply":"2025-09-01T10:19:26.713076Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"((428, 36), (86, 36))"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# train models and store MCCs in a dictionary as follow: {model_name: MCC}\nmodels.update(\n    {\n        'AAI_SVM' : SVM(X_train, y_train, X_test, y_test),\n        'AAI_DT' : Tree(X_train, y_train, X_test, y_test),\n        'AAI_NB' : NaiveBayes(X_train, y_train, X_test, y_test),\n        'AAI_KNN': KNN(X_train, y_train, X_test, y_test),\n        'AAI_LR': LRegression(X_train, y_train, X_test, y_test),\n        'AAI_RF': RandomForest(X_train, y_train, X_test, y_test),\n        'AAI_ADA': ADABoost(X_train, y_train, X_test, y_test),\n        'AAI_MLP': MLPClassify(X_train, y_train, X_test, y_test)\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T10:19:26.714584Z","iopub.execute_input":"2025-09-01T10:19:26.714894Z","iopub.status.idle":"2025-09-01T11:57:54.617135Z","shell.execute_reply.started":"2025-09-01T10:19:26.714864Z","shell.execute_reply":"2025-09-01T11:57:54.616227Z"}},"outputs":[{"name":"stdout","text":"\n Test Results SVM\n\nBest accuracy and parameters are:  0.7193798449612403 {'C': 1, 'kernel': 'linear'}\nAccuracy: 0.7441860465116279\nMCC: 0.48917748917748916\n\n Test Results Decision Tree\n\nBest accuracy and parameters are:  0.66578073089701 {'criterion': 'gini', 'max_depth': 7}\nAccuracy: 0.7093023255813954\nMCC: 0.4187178946793119\n\n Test Results Naive Bayes\n\nBest accuracy and parameters are:  0.5934108527131782 {'var_smoothing': 0.01}\nAccuracy: 0.5930232558139535\nMCC: 0.18473394347360944\n\n Test Results KNN\n\nBest accuracy and parameters are:  0.6215393133997785 {'metric': 'manhattan', 'n_neighbors': 8}\nAccuracy: 0.686046511627907\nMCC: 0.37914871197798117\n\n Test Results LR\n\nBest accuracy and parameters are:  0.6937430786267995 {'penalty': 'l2'}\nAccuracy: 0.7093023255813954\nMCC: 0.42025467427280044\n\n Test Results RF\n\nBest accuracy and parameters are:  0.7287375415282392 {'max_features': 'auto', 'max_depth': 17, 'criterion': 'gini'}\nAccuracy: 0.7906976744186046\nMCC: 0.5813462701261382\n\n Test Results ADABoost\n\nBest accuracy and parameters are:  0.74734219269103 {'estimator__criterion': 'gini', 'estimator__max_depth': 4, 'estimator__splitter': 'random'}\nAccuracy: 0.686046511627907\nMCC: 0.37259282646827546\n\n Test Results MLP\n\nBest accuracy and parameters are:  0.6517718715393135 {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\nAccuracy: 0.6511627906976745\nMCC: 0.30174936461590124\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"### BPNC","metadata":{}},{"cell_type":"code","source":"# BPNC\ndef BPNC(seqs):\n    encodings = []\n    for fastas in seqs:\n        fastas_NT5 = \"%s\" % fastas[:2]\n        fastas_CT5 = \"%s\" % fastas[-2:]\n        full = fastas_NT5 + fastas_CT5\n        encoding = []\n        for AA in full:\n            for AA1 in letters:\n                tag = 1 if AA == AA1 else 0\n                encoding.append(tag)\n        encodings.append(encoding)\n    return encodings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:57:54.618210Z","iopub.execute_input":"2025-09-01T11:57:54.618469Z","iopub.status.idle":"2025-09-01T11:57:54.624280Z","shell.execute_reply.started":"2025-09-01T11:57:54.618446Z","shell.execute_reply":"2025-09-01T11:57:54.623363Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Compute encodings\ntrain_encodings_result = BPNC(train['sequence'].tolist())\ntest_encodings_result = BPNC(test['sequence'].tolist())\n\nX_train = pd.DataFrame(train_encodings_result)\nX_test = pd.DataFrame(test_encodings_result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:57:54.625255Z","iopub.execute_input":"2025-09-01T11:57:54.625558Z","iopub.status.idle":"2025-09-01T11:57:54.650689Z","shell.execute_reply.started":"2025-09-01T11:57:54.625524Z","shell.execute_reply":"2025-09-01T11:57:54.650127Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:57:54.651358Z","iopub.execute_input":"2025-09-01T11:57:54.651544Z","iopub.status.idle":"2025-09-01T11:57:54.656441Z","shell.execute_reply.started":"2025-09-01T11:57:54.651528Z","shell.execute_reply":"2025-09-01T11:57:54.655792Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"((428, 80), (86, 80))"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"# train models and store MCCs in a dictionary as follow: {model_name: MCC}\nmodels.update(\n    {\n        'BPNC_SVM' : SVM(X_train, y_train, X_test, y_test),\n        'BPNC_DT' : Tree(X_train, y_train, X_test, y_test),\n        'BPNC_NB' : NaiveBayes(X_train, y_train, X_test, y_test),\n        'BPNC_KNN': KNN(X_train, y_train, X_test, y_test),\n        'BPNC_LR': LRegression(X_train, y_train, X_test, y_test),\n        'BPNC_RF': RandomForest(X_train, y_train, X_test, y_test),\n        'BPNC_ADA': ADABoost(X_train, y_train, X_test, y_test),\n        'BPNC_MLP': MLPClassify(X_train, y_train, X_test, y_test)\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T11:57:54.657300Z","iopub.execute_input":"2025-09-01T11:57:54.657562Z","iopub.status.idle":"2025-09-01T12:08:42.769283Z","shell.execute_reply.started":"2025-09-01T11:57:54.657531Z","shell.execute_reply":"2025-09-01T12:08:42.768404Z"}},"outputs":[{"name":"stdout","text":"\n Test Results SVM\n\nBest accuracy and parameters are:  0.7801218161683278 {'C': 10, 'kernel': 'rbf'}\nAccuracy: 0.813953488372093\nMCC: 0.6279841238862575\n\n Test Results Decision Tree\n\nBest accuracy and parameters are:  0.7336655592469545 {'criterion': 'entropy', 'max_depth': 18}\nAccuracy: 0.813953488372093\nMCC: 0.6279841238862575\n\n Test Results Naive Bayes\n\nBest accuracy and parameters are:  0.740420819490587 {'var_smoothing': 0.001}\nAccuracy: 0.7558139534883721\nMCC: 0.5252647794285569\n\n Test Results KNN\n\nBest accuracy and parameters are:  0.7591915836101883 {'metric': 'minkowski', 'n_neighbors': 9}\nAccuracy: 0.7906976744186046\nMCC: 0.5846000738768441\n\n Test Results LR\n\nBest accuracy and parameters are:  0.7406423034330011 {'penalty': None}\nAccuracy: 0.7674418604651163\nMCC: 0.5359591602564021\n\n Test Results RF\n\nBest accuracy and parameters are:  0.7522702104097453 {'max_features': 'log2', 'max_depth': 15, 'criterion': 'entropy'}\nAccuracy: 0.872093023255814\nMCC: 0.7441107248077677\n\n Test Results ADABoost\n\nBest accuracy and parameters are:  0.777796234772979 {'estimator__criterion': 'entropy', 'estimator__max_depth': 5, 'estimator__splitter': 'random'}\nAccuracy: 0.813953488372093\nMCC: 0.6287878787878788\n\n Test Results MLP\n\nBest accuracy and parameters are:  0.7941860465116279 {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'adam'}\nAccuracy: 0.8255813953488372\nMCC: 0.6531277540889141\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"### CTD","metadata":{}},{"cell_type":"code","source":"group1 = {\n    \"hydrophobicity_PRAM900101\": \"RKEDQN\",\n    \"normwaalsvolume\": \"GASTPDC\",\n    \"polarity\": \"LIFWCMVY\",\n    \"polarizability\": \"GASDT\",\n    \"charge\": \"KR\",\n    \"secondarystruct\": \"EALMQKRH\",\n    \"solventaccess\": \"ALFCGIVW\",\n}\ngroup2 = {\n    \"hydrophobicity_PRAM900101\": \"GASTPHY\",\n    \"normwaalsvolume\": \"NVEQIL\",\n    \"polarity\": \"PATGS\",\n    \"polarizability\": \"CPNVEQIL\",\n    \"charge\": \"ANCQGHILMFPSTWYV\",\n    \"secondarystruct\": \"VIYCWFT\",\n    \"solventaccess\": \"RKQEND\",\n}\ngroup3 = {\n    \"hydrophobicity_PRAM900101\": \"CLVIMFW\",\n    \"normwaalsvolume\": \"MHKFRYW\",\n    \"polarity\": \"HQRKNED\",\n    \"polarizability\": \"KMHFRYW\",\n    \"charge\": \"DE\",\n    \"secondarystruct\": \"GNPSD\",\n    \"solventaccess\": \"MSPTHY\",\n}\ngroups = [group1, group2, group3]\npropertys = (\n    \"hydrophobicity_PRAM900101\",\n    \"normwaalsvolume\",\n    \"polarity\",\n    \"polarizability\",\n    \"charge\",\n    \"secondarystruct\",\n    \"solventaccess\",\n)\n\n\ndef Count_C(sequence1, sequence2):\n    sum = 0\n    for aa in sequence1:\n        sum = sum + sequence2.count(aa)\n    return sum\n\n\ndef Count_D(aaSet, sequence):\n    number = 0\n    for aa in sequence:\n        if aa in aaSet:\n            number = number + 1\n    cutoffNums = [\n        1,\n        math.floor(0.25 * number),\n        math.floor(0.50 * number),\n        math.floor(0.75 * number),\n        number,\n    ]\n    cutoffNums = [i if i >= 1 else 1 for i in cutoffNums]\n    code = []\n    for cutoff in cutoffNums:\n        myCount = 0\n        for i in range(len(sequence)):\n            if sequence[i] in aaSet:\n                myCount += 1\n                if myCount == cutoff:\n                    code.append((i + 1) / len(sequence))\n                    break\n        if myCount == 0:\n            code.append(0)\n    return code\n\n\ndef CTD(seqs):\n    encodings = []\n    for seq in seqs:\n        code = []\n        code2 = []\n        CTDD1 = []\n        CTDD2 = []\n        CTDD3 = []\n        aaPair = [seq[j : j + 2] for j in range(len(seq) - 1)]\n        for p in propertys:\n            c1 = Count_C(group1[p], seq) / len(seq)\n            c2 = Count_C(group2[p], seq) / len(seq)\n            c3 = 1 - c1 - c2\n            code = code + [c1, c2, c3]\n\n            c1221, c1331, c2332 = 0, 0, 0\n            for pair in aaPair:\n                if (pair[0] in group1[p] and pair[1] in group2[p]) or (\n                    pair[0] in group2[p] and pair[1] in group1[p]\n                ):\n                    c1221 = c1221 + 1\n                    continue\n                if (pair[0] in group1[p] and pair[1] in group3[p]) or (\n                    pair[0] in group3[p] and pair[1] in group1[p]\n                ):\n                    c1331 = c1331 + 1\n                    continue\n                if (pair[0] in group2[p] and pair[1] in group3[p]) or (\n                    pair[0] in group3[p] and pair[1] in group2[p]\n                ):\n                    c2332 = c2332 + 1\n            code2 = code2 + [\n                c1221 / len(aaPair),\n                c1331 / len(aaPair),\n                c2332 / len(aaPair),\n            ]\n            CTDD1 = CTDD1 + [\n                value / float(len(seq)) for value in Count_D(group1[p], seq)\n            ]\n            CTDD2 = CTDD2 + [\n                value / float(len(seq)) for value in Count_D(group2[p], seq)\n            ]\n            CTDD3 = CTDD3 + [\n                value / float(len(seq)) for value in Count_D(group3[p], seq)\n            ]\n        encodings.append(code + code2 + CTDD1 + CTDD2 + CTDD3)\n    return encodings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:08:42.770371Z","iopub.execute_input":"2025-09-01T12:08:42.770701Z","iopub.status.idle":"2025-09-01T12:08:42.782913Z","shell.execute_reply.started":"2025-09-01T12:08:42.770668Z","shell.execute_reply":"2025-09-01T12:08:42.782223Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Compute encodings\ntrain_encodings_result = CTD(train['sequence'].tolist())\ntest_encodings_result = CTD(test['sequence'].tolist())\n\nX_train = pd.DataFrame(train_encodings_result)\nX_test = pd.DataFrame(test_encodings_result)\n\ny_train = train['label']\ny_test = test['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:08:42.783795Z","iopub.execute_input":"2025-09-01T12:08:42.784023Z","iopub.status.idle":"2025-09-01T12:08:42.880538Z","shell.execute_reply.started":"2025-09-01T12:08:42.784005Z","shell.execute_reply":"2025-09-01T12:08:42.879901Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:08:42.881340Z","iopub.execute_input":"2025-09-01T12:08:42.881615Z","iopub.status.idle":"2025-09-01T12:08:42.886460Z","shell.execute_reply.started":"2025-09-01T12:08:42.881594Z","shell.execute_reply":"2025-09-01T12:08:42.885697Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"((428, 147), (86, 147))"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"svm, mcc = SVM(X_train, y_train, X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:08:42.887293Z","iopub.execute_input":"2025-09-01T12:08:42.887586Z","iopub.status.idle":"2025-09-01T12:08:51.328828Z","shell.execute_reply.started":"2025-09-01T12:08:42.887556Z","shell.execute_reply":"2025-09-01T12:08:51.327969Z"}},"outputs":[{"name":"stdout","text":"\n Test Results SVM\n\nBest accuracy and parameters are:  0.7919712070874861 {'C': 1, 'kernel': 'rbf'}\nAccuracy: 0.872093023255814\nMCC: 0.7441107248077677\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# train models and store MCCs in a dictionary as follow: {model_name: MCC}\nmodels.update(\n    {\n        'CTD_SVM' : SVM(X_train, y_train, X_test, y_test),\n        'CTD_DT' : Tree(X_train, y_train, X_test, y_test),\n        'CTD_NB' : NaiveBayes(X_train, y_train, X_test, y_test),\n        'CTD_KNN': KNN(X_train, y_train, X_test, y_test),\n        'CTD_LR': LRegression(X_train, y_train, X_test, y_test),\n        'CTD_RF': RandomForest(X_train, y_train, X_test, y_test),\n        'CTD_ADA': ADABoost(X_train, y_train, X_test, y_test),\n        'CTD_MLP': MLPClassify(X_train, y_train, X_test, y_test)\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:08:51.329652Z","iopub.execute_input":"2025-09-01T12:08:51.329971Z","iopub.status.idle":"2025-09-01T12:24:55.401170Z","shell.execute_reply.started":"2025-09-01T12:08:51.329941Z","shell.execute_reply":"2025-09-01T12:24:55.400090Z"}},"outputs":[{"name":"stdout","text":"\n Test Results SVM\n\nBest accuracy and parameters are:  0.7919712070874861 {'C': 1, 'kernel': 'rbf'}\nAccuracy: 0.872093023255814\nMCC: 0.7441107248077677\n\n Test Results Decision Tree\n\nBest accuracy and parameters are:  0.7266888150609081 {'criterion': 'gini', 'max_depth': 12}\nAccuracy: 0.7674418604651163\nMCC: 0.5414058996899022\n\n Test Results Naive Bayes\n\nBest accuracy and parameters are:  0.6168881506090809 {'var_smoothing': 1e-09}\nAccuracy: 0.6511627906976745\nMCC: 0.3042780159121981\n\n Test Results KNN\n\nBest accuracy and parameters are:  0.7477297895902547 {'metric': 'minkowski', 'n_neighbors': 3}\nAccuracy: 0.8023255813953488\nMCC: 0.6065531381256913\n\n Test Results LR\n\nBest accuracy and parameters are:  0.7638981173864895 {'penalty': 'l2'}\nAccuracy: 0.8255813953488372\nMCC: 0.6513389472789296\n\n Test Results RF\n\nBest accuracy and parameters are:  0.7898117386489479 {'max_features': 'log2', 'max_depth': 15, 'criterion': 'entropy'}\nAccuracy: 0.8488372093023255\nMCC: 0.6975361088445451\n\n Test Results ADABoost\n\nBest accuracy and parameters are:  0.7781284606866002 {'estimator__criterion': 'entropy', 'estimator__max_depth': 4, 'estimator__splitter': 'best'}\nAccuracy: 0.7790697674418605\nMCC: 0.5628951924666452\n\n Test Results MLP\n\nBest accuracy and parameters are:  0.7896456256921374 {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\nAccuracy: 0.8488372093023255\nMCC: 0.6975361088445451\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"### DPC","metadata":{}},{"cell_type":"code","source":"# DPC\ndiPeptides = [aa1 + aa2 for aa1 in letters for aa2 in letters]\n\n\ndef DPC(seqs):\n    encodings = []\n    for seq in seqs:\n        AADict = {}\n        for aa in range(len(letters)):\n            AADict[letters[aa]] = aa\n\n        tmpCode = [0] * 400\n        for j in range(len(seq) - 2 + 1):\n            tmpCode[AADict[seq[j]] * 20 + AADict[seq[j + 1]]] = (\n                tmpCode[AADict[seq[j]] * 20 + AADict[seq[j + 1]]] + 1\n            )\n        if sum(tmpCode) != 0:\n            tmpDPC = [i / sum(tmpCode) for i in tmpCode]\n        encodings.append(tmpDPC)\n    return encodings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:24:55.402039Z","iopub.execute_input":"2025-09-01T12:24:55.402354Z","iopub.status.idle":"2025-09-01T12:24:55.408247Z","shell.execute_reply.started":"2025-09-01T12:24:55.402331Z","shell.execute_reply":"2025-09-01T12:24:55.407494Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# Compute encodings\ntrain_encodings_result = DPC(train['sequence'].tolist())\ntest_encodings_result = DPC(test['sequence'].tolist())\n\nX_train = pd.DataFrame(train_encodings_result)\nX_test = pd.DataFrame(test_encodings_result)\n\ny_train = train['label']\ny_test = test['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:24:55.409005Z","iopub.execute_input":"2025-09-01T12:24:55.409220Z","iopub.status.idle":"2025-09-01T12:24:55.937918Z","shell.execute_reply.started":"2025-09-01T12:24:55.409202Z","shell.execute_reply":"2025-09-01T12:24:55.937233Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:24:55.938641Z","iopub.execute_input":"2025-09-01T12:24:55.938917Z","iopub.status.idle":"2025-09-01T12:24:55.943979Z","shell.execute_reply.started":"2025-09-01T12:24:55.938891Z","shell.execute_reply":"2025-09-01T12:24:55.943298Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"((428, 400), (86, 400))"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# train models and store MCCs in a dictionary as follow: {model_name: MCC}\nmodels.update(\n    {\n        'DPC_SVM' : SVM(X_train, y_train, X_test, y_test),\n        'DPC_DT' : Tree(X_train, y_train, X_test, y_test),\n        'DPC_NB' : NaiveBayes(X_train, y_train, X_test, y_test),\n        'DPC_KNN': KNN(X_train, y_train, X_test, y_test),\n        'DPC_LR': LRegression(X_train, y_train, X_test, y_test),\n        'DPC_RF': RandomForest(X_train, y_train, X_test, y_test),\n        'DPC_ADA': ADABoost(X_train, y_train, X_test, y_test),\n        'DPC_MLP': MLPClassify(X_train, y_train, X_test, y_test)\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:24:55.946798Z","iopub.execute_input":"2025-09-01T12:24:55.947020Z","iopub.status.idle":"2025-09-01T12:36:50.974942Z","shell.execute_reply.started":"2025-09-01T12:24:55.946996Z","shell.execute_reply":"2025-09-01T12:36:50.974042Z"}},"outputs":[{"name":"stdout","text":"\n Test Results SVM\n\nBest accuracy and parameters are:  0.7638981173864895 {'C': 1, 'kernel': 'rbf'}\nAccuracy: 0.813953488372093\nMCC: 0.6277056277056277\n\n Test Results Decision Tree\n\nBest accuracy and parameters are:  0.6143964562569214 {'criterion': 'gini', 'max_depth': 3}\nAccuracy: 0.6046511627906976\nMCC: 0.27790254988003843\n\n Test Results Naive Bayes\n\nBest accuracy and parameters are:  0.7218715393133996 {'var_smoothing': 0.01}\nAccuracy: 0.7674418604651163\nMCC: 0.5357142857142857\n\n Test Results KNN\n\nBest accuracy and parameters are:  0.6984496124031007 {'metric': 'manhattan', 'n_neighbors': 7}\nAccuracy: 0.7209302325581395\nMCC: 0.45629995342467633\n\n Test Results LR\n\nBest accuracy and parameters are:  0.7241971207087485 {'penalty': 'l2'}\nAccuracy: 0.7441860465116279\nMCC: 0.5125886314693656\n\n Test Results RF\n\nBest accuracy and parameters are:  0.6937430786267995 {'max_features': 'log2', 'max_depth': 15, 'criterion': 'entropy'}\nAccuracy: 0.8255813953488372\nMCC: 0.6531277540889141\n\n Test Results ADABoost\n\nBest accuracy and parameters are:  0.7105204872646733 {'estimator__criterion': 'gini', 'estimator__max_depth': 4, 'estimator__splitter': 'random'}\nAccuracy: 0.686046511627907\nMCC: 0.37368005830957773\n\n Test Results MLP\n\nBest accuracy and parameters are:  0.6918050941306755 {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'adam'}\nAccuracy: 0.7325581395348837\nMCC: 0.4727951768804542\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"### GTPC","metadata":{}},{"cell_type":"code","source":"# GTPC\ngroup = {\n    \"alphatic\": \"GAVLMI\",\n    \"aromatic\": \"FYW\",\n    \"postivecharge\": \"KRH\",\n    \"negativecharge\": \"DE\",\n    \"uncharge\": \"STCPNQ\",\n}\ngroupKey = group.keys()\ntripeptide = [\n    g1 + \".\" + g2 + \".\" + g3 for g1 in groupKey for g2 in groupKey for g3 in groupKey\n]\n\n\ndef GTPC(seqs):\n    encodings = []\n    for seq in seqs:\n        index = {}\n        myDict = {}\n        for key in groupKey:\n            for aa in group[key]:\n                index[aa] = key\n        for t in tripeptide:\n            myDict[t] = 0\n        sum = 0\n        for j in range(len(seq) - 2):\n            myDict[\n                index[seq[j]] + \".\" + index[seq[j + 1]] + \".\" + index[seq[j + 2]]\n            ] = (\n                myDict[\n                    index[seq[j]] + \".\" + index[seq[j + 1]] + \".\" + index[seq[j + 2]]\n                ]\n                + 1\n            )\n            sum = sum + 1\n        code = []\n        if sum == 0:\n            for t in tripeptide:\n                code.append(0)\n        else:\n            for t in tripeptide:\n                code.append(myDict[t] / sum)\n        encodings.append(code)\n    return encodings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:36:50.976191Z","iopub.execute_input":"2025-09-01T12:36:50.976453Z","iopub.status.idle":"2025-09-01T12:36:50.983288Z","shell.execute_reply.started":"2025-09-01T12:36:50.976430Z","shell.execute_reply":"2025-09-01T12:36:50.982350Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Compute encodings\ntrain_encodings_result = GTPC(train['sequence'].tolist())\ntest_encodings_result = GTPC(test['sequence'].tolist())\n\nX_train = pd.DataFrame(train_encodings_result)\nX_test = pd.DataFrame(test_encodings_result)\n\ny_train = train['label']\ny_test = test['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:36:50.984244Z","iopub.execute_input":"2025-09-01T12:36:50.984536Z","iopub.status.idle":"2025-09-01T12:36:51.020616Z","shell.execute_reply.started":"2025-09-01T12:36:50.984510Z","shell.execute_reply":"2025-09-01T12:36:51.019800Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:36:51.021591Z","iopub.execute_input":"2025-09-01T12:36:51.021911Z","iopub.status.idle":"2025-09-01T12:36:51.026738Z","shell.execute_reply.started":"2025-09-01T12:36:51.021885Z","shell.execute_reply":"2025-09-01T12:36:51.025858Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"((428, 125), (86, 125))"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"# train models and store MCCs in a dictionary as follow: {model_name: MCC}\nmodels.update(\n    {\n        'GTPC_SVM' : SVM(X_train, y_train, X_test, y_test),\n        'GTPC_DT' : Tree(X_train, y_train, X_test, y_test),\n        'GTPC_NB' : NaiveBayes(X_train, y_train, X_test, y_test),\n        'GTPC_KNN': KNN(X_train, y_train, X_test, y_test),\n        'GTPC_LR': LRegression(X_train, y_train, X_test, y_test),\n        'GTPC_RF': RandomForest(X_train, y_train, X_test, y_test),\n        'GTPC_ADA': ADABoost(X_train, y_train, X_test, y_test),\n        'GTPC_MLP': MLPClassify(X_train, y_train, X_test, y_test)\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:36:51.027562Z","iopub.execute_input":"2025-09-01T12:36:51.027839Z","iopub.status.idle":"2025-09-01T12:43:56.112392Z","shell.execute_reply.started":"2025-09-01T12:36:51.027809Z","shell.execute_reply":"2025-09-01T12:43:56.111554Z"}},"outputs":[{"name":"stdout","text":"\n Test Results SVM\n\nBest accuracy and parameters are:  0.6965116279069768 {'C': 1, 'kernel': 'linear'}\nAccuracy: 0.686046511627907\nMCC: 0.3832120403378151\n\n Test Results Decision Tree\n\nBest accuracy and parameters are:  0.65437430786268 {'criterion': 'gini', 'max_depth': 12}\nAccuracy: 0.5930232558139535\nMCC: 0.22244170101371633\n\n Test Results Naive Bayes\n\nBest accuracy and parameters are:  0.6684385382059801 {'var_smoothing': 0.01}\nAccuracy: 0.686046511627907\nMCC: 0.37914871197798117\n\n Test Results KNN\n\nBest accuracy and parameters are:  0.6636766334440753 {'metric': 'minkowski', 'n_neighbors': 7}\nAccuracy: 0.6162790697674418\nMCC: 0.24900558852795376\n\n Test Results LR\n\nBest accuracy and parameters are:  0.6918604651162792 {'penalty': 'l2'}\nAccuracy: 0.6627906976744186\nMCC: 0.32926108748531563\n\n Test Results RF\n\nBest accuracy and parameters are:  0.6942414174972313 {'max_features': 'log2', 'max_depth': 15, 'criterion': 'entropy'}\nAccuracy: 0.6627906976744186\nMCC: 0.3459036908510489\n\n Test Results ADABoost\n\nBest accuracy and parameters are:  0.677796234772979 {'estimator__criterion': 'gini', 'estimator__max_depth': 4, 'estimator__splitter': 'best'}\nAccuracy: 0.6627906976744186\nMCC: 0.32926108748531563\n\n Test Results MLP\n\nBest accuracy and parameters are:  0.6962901439645626 {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'adam'}\nAccuracy: 0.7093023255813954\nMCC: 0.42025467427280044\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:43:56.114137Z","iopub.execute_input":"2025-09-01T12:43:56.114389Z","iopub.status.idle":"2025-09-01T12:43:56.143575Z","shell.execute_reply.started":"2025-09-01T12:43:56.114369Z","shell.execute_reply":"2025-09-01T12:43:56.142713Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"{'ESM_SVM': (SVC(C=10, probability=True, random_state=42), 0.7441107248077677),\n 'ESM_DT': (DecisionTreeClassifier(max_depth=6, random_state=42),\n  0.6746219776463768),\n 'ESM_NB': (GaussianNB(var_smoothing=0.01), 0.6819317770742027),\n 'ESM_KNN': (KNeighborsClassifier(metric='manhattan', n_neighbors=7),\n  0.6997023700521369),\n 'ESM_LR': (LogisticRegression(max_iter=1500, random_state=42),\n  0.7441107248077677),\n 'ESM_RF': (RandomForestClassifier(criterion='entropy', max_depth=9, max_features='log2',\n                         random_state=42),\n  0.7711514889173213),\n 'ESM_ADA': (AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=5,\n                                                      random_state=42),\n                     random_state=42),\n  0.721259831406496),\n 'ESM_MLP': (MLPClassifier(max_iter=1000, random_state=42),\n  0.8177893426774406),\n 'AAE_SVM': (SVC(C=1, probability=True, random_state=42), 0.44015540360100736),\n 'AAE_DT': (DecisionTreeClassifier(max_depth=16, random_state=42),\n  0.3697869984767234),\n 'AAE_NB': (GaussianNB(var_smoothing=1e-05), 0.4193309519544422),\n 'AAE_KNN': (KNeighborsClassifier(metric='manhattan', n_neighbors=1),\n  0.3478516235216784),\n 'AAE_LR': (LogisticRegression(max_iter=1500, random_state=42),\n  0.3982469291220737),\n 'AAE_RF': (RandomForestClassifier(max_depth=5, random_state=42),\n  0.3912213018462842),\n 'AAE_ADA': (AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1,\n                                                      random_state=42,\n                                                      splitter='random'),\n                     random_state=42),\n  0.3912213018462842),\n 'AAE_MLP': (MLPClassifier(max_iter=1000, random_state=42),\n  0.3982469291220737),\n 'AAI_SVM': (SVC(C=1, kernel='linear', probability=True, random_state=42),\n  0.48917748917748916),\n 'AAI_DT': (DecisionTreeClassifier(max_depth=7, random_state=42),\n  0.4187178946793119),\n 'AAI_NB': (GaussianNB(var_smoothing=0.01), 0.18473394347360944),\n 'AAI_KNN': (KNeighborsClassifier(metric='manhattan', n_neighbors=8),\n  0.37914871197798117),\n 'AAI_LR': (LogisticRegression(max_iter=1500, random_state=42),\n  0.42025467427280044),\n 'AAI_RF': (RandomForestClassifier(max_depth=17, max_features='auto', random_state=42),\n  0.5813462701261382),\n 'AAI_ADA': (AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=4,\n                                                      random_state=42,\n                                                      splitter='random'),\n                     random_state=42),\n  0.37259282646827546),\n 'AAI_MLP': (MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 50),\n                max_iter=1000, random_state=42),\n  0.30174936461590124),\n 'BPNC_SVM': (SVC(C=10, probability=True, random_state=42),\n  0.6279841238862575),\n 'BPNC_DT': (DecisionTreeClassifier(criterion='entropy', max_depth=18, random_state=42),\n  0.6279841238862575),\n 'BPNC_NB': (GaussianNB(var_smoothing=0.001), 0.5252647794285569),\n 'BPNC_KNN': (KNeighborsClassifier(n_neighbors=9), 0.5846000738768441),\n 'BPNC_LR': (LogisticRegression(max_iter=1500, penalty=None, random_state=42),\n  0.5359591602564021),\n 'BPNC_RF': (RandomForestClassifier(criterion='entropy', max_depth=15, max_features='log2',\n                         random_state=42),\n  0.7441107248077677),\n 'BPNC_ADA': (AdaBoostClassifier(estimator=DecisionTreeClassifier(criterion='entropy',\n                                                      max_depth=5,\n                                                      random_state=42,\n                                                      splitter='random'),\n                     random_state=42),\n  0.6287878787878788),\n 'BPNC_MLP': (MLPClassifier(alpha=0.01, hidden_layer_sizes=(50,), max_iter=1000,\n                random_state=42),\n  0.6531277540889141),\n 'CTD_SVM': (SVC(C=1, probability=True, random_state=42), 0.7441107248077677),\n 'CTD_DT': (DecisionTreeClassifier(max_depth=12, random_state=42),\n  0.5414058996899022),\n 'CTD_NB': (GaussianNB(), 0.3042780159121981),\n 'CTD_KNN': (KNeighborsClassifier(n_neighbors=3), 0.6065531381256913),\n 'CTD_LR': (LogisticRegression(max_iter=1500, random_state=42),\n  0.6513389472789296),\n 'CTD_RF': (RandomForestClassifier(criterion='entropy', max_depth=15, max_features='log2',\n                         random_state=42),\n  0.6975361088445451),\n 'CTD_ADA': (AdaBoostClassifier(estimator=DecisionTreeClassifier(criterion='entropy',\n                                                      max_depth=4,\n                                                      random_state=42),\n                     random_state=42),\n  0.5628951924666452),\n 'CTD_MLP': (MLPClassifier(alpha=0.001, max_iter=1000, random_state=42),\n  0.6975361088445451),\n 'DPC_SVM': (SVC(C=1, probability=True, random_state=42), 0.6277056277056277),\n 'DPC_DT': (DecisionTreeClassifier(max_depth=3, random_state=42),\n  0.27790254988003843),\n 'DPC_NB': (GaussianNB(var_smoothing=0.01), 0.5357142857142857),\n 'DPC_KNN': (KNeighborsClassifier(metric='manhattan', n_neighbors=7),\n  0.45629995342467633),\n 'DPC_LR': (LogisticRegression(max_iter=1500, random_state=42),\n  0.5125886314693656),\n 'DPC_RF': (RandomForestClassifier(criterion='entropy', max_depth=15, max_features='log2',\n                         random_state=42),\n  0.6531277540889141),\n 'DPC_ADA': (AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=4,\n                                                      random_state=42,\n                                                      splitter='random'),\n                     random_state=42),\n  0.37368005830957773),\n 'DPC_MLP': (MLPClassifier(activation='logistic', alpha=0.01, hidden_layer_sizes=(50,),\n                max_iter=1000, random_state=42),\n  0.4727951768804542),\n 'GTPC_SVM': (SVC(C=1, kernel='linear', probability=True, random_state=42),\n  0.3832120403378151),\n 'GTPC_DT': (DecisionTreeClassifier(max_depth=12, random_state=42),\n  0.22244170101371633),\n 'GTPC_NB': (GaussianNB(var_smoothing=0.01), 0.37914871197798117),\n 'GTPC_KNN': (KNeighborsClassifier(n_neighbors=7), 0.24900558852795376),\n 'GTPC_LR': (LogisticRegression(max_iter=1500, random_state=42),\n  0.32926108748531563),\n 'GTPC_RF': (RandomForestClassifier(criterion='entropy', max_depth=15, max_features='log2',\n                         random_state=42),\n  0.3459036908510489),\n 'GTPC_ADA': (AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=4,\n                                                      random_state=42),\n                     random_state=42),\n  0.32926108748531563),\n 'GTPC_MLP': (MLPClassifier(activation='logistic', alpha=0.001, hidden_layer_sizes=(50,),\n                max_iter=1000, random_state=42),\n  0.42025467427280044)}"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"# Sort the models dictionary by MCC value in descending order\ntop_models = sorted(models.items(), key=lambda item: item[1][1], reverse=True)[:8]\n\n# Convert the result into a dictionary if needed\ntop_models_dict = dict(top_models)\n\n# Print the top 8 models\nprint(\"Top 8 models based on MCC values:\")\nfor model_name, (model, mcc) in top_models:\n    print(f\"Model: {model_name}, MCC: {mcc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:44:02.580266Z","iopub.execute_input":"2025-09-01T12:44:02.580590Z","iopub.status.idle":"2025-09-01T12:44:02.587998Z","shell.execute_reply.started":"2025-09-01T12:44:02.580563Z","shell.execute_reply":"2025-09-01T12:44:02.586848Z"}},"outputs":[{"name":"stdout","text":"Top 8 models based on MCC values:\nModel: ESM_MLP, MCC: 0.8177893426774406\nModel: ESM_RF, MCC: 0.7711514889173213\nModel: ESM_SVM, MCC: 0.7441107248077677\nModel: ESM_LR, MCC: 0.7441107248077677\nModel: BPNC_RF, MCC: 0.7441107248077677\nModel: CTD_SVM, MCC: 0.7441107248077677\nModel: ESM_ADA, MCC: 0.721259831406496\nModel: ESM_KNN, MCC: 0.6997023700521369\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# # Sort the models dictionary by MCC value in descending order\n# top_models = sorted(models.items(), key=lambda item: item[1][1], reverse=True)[:6]\n\n# # Convert the result into a dictionary if needed\n# top_models_dict = dict(top_models)\n\n# # Print the top 8 models\n# print(\"Top 8 models based on MCC values:\")\n# for model_name, (model, mcc) in top_models:\n#     print(f\"Model: {model_name}, MCC: {mcc}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generate Probability Dataset","metadata":{}},{"cell_type":"code","source":"# mapping for encoding function names to actual functions\nencoding_function_map = {\n    \"AAE\": AAE,\n    \"AAI\": AAI,\n    \"BPNC\": BPNC,\n    \"CTD\": CTD,\n    \"DPC\": DPC,\n    \"GTPC\": GTPC,\n    \"ESM\": ESM\n}\n\ndef compute_mcc(y,y_p):\n    TP, FP, FN, TN = confusion_matrix(y, y_p).ravel()\n    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n    return MCC\n    \ndef generate_probabilities(train, test, encoding_func_name, encoding_func, classifier):\n    # Compute encodings\n    print(\"Classifier: \", classifier)\n    if encoding_func_name == \"ESM\":\n        print(\"Using ESM encoding\")\n        X_train, X_test = encoding_func()\n    else:\n        train_encodings_result = encoding_func(train['sequence'].tolist())\n        test_encodings_result = encoding_func(test['sequence'].tolist())\n        \n        X_train = pd.DataFrame(train_encodings_result)\n        X_test = pd.DataFrame(test_encodings_result)\n    \n    y_train = train['label']\n    y_test = test['label']\n\n    # Check if classifier supports predict_proba or decision_function\n    if hasattr(classifier, \"predict_proba\"):\n        print(\"PREDICT PROB\")\n        train_proba = classifier.predict_proba(X_train)[:, 1]  # Get probability for positive class\n        test_proba = classifier.predict_proba(X_test)[:, 1]\n    elif hasattr(classifier, \"decision_function\"):\n        print(\"Decision\")\n        train_proba = classifier.decision_function(X_train)  # Use decision function output\n        test_proba = classifier.decision_function(X_test)\n    else:\n        raise ValueError(f\"Classifier {classifier.__class__.__name__} does not support probability estimation.\")\n\n    y_train_p = classifier.predict(X_train)\n    y_test_p = classifier.predict(X_test)\n    \n    Train_MCC = compute_mcc(y_train, y_train_p)\n    Test_MCC = compute_mcc(y_test, y_test_p)\n\n    print(f\"MCC values for encoding {encoding_func} and classifier {classifier.__class__.__name__}\")\n    print(\"Training set\", Train_MCC)\n    print(\"Test set\", Test_MCC)\n    \n    return train_proba, test_proba\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:44:20.239242Z","iopub.execute_input":"2025-09-01T12:44:20.239556Z","iopub.status.idle":"2025-09-01T12:44:20.247305Z","shell.execute_reply.started":"2025-09-01T12:44:20.239532Z","shell.execute_reply":"2025-09-01T12:44:20.246389Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# Initialize empty DataFrames outside the loop\ntrain_prob_df = pd.DataFrame()\ntest_prob_df = pd.DataFrame()\n\nfor key in top_models_dict.keys():\n    classifier = top_models_dict[key][0]\n    encoding_func_name = key.split(\"_\")[0]\n    \n    # Get the actual encoding function from the map\n    encoding_func = encoding_function_map.get(encoding_func_name)\n    if encoding_func is None:\n        raise ValueError(f\"Encoding function {encoding_func_name} not found in the map.\")\n\n    train_proba, test_proba = generate_probabilities(train, test, encoding_func_name, encoding_func, classifier)\n\n    # Update train_prob_df\n    train_prob_df[key] = train_proba\n\n    # Update test_prob_df\n    test_prob_df[key] = test_proba","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:44:23.609423Z","iopub.execute_input":"2025-09-01T12:44:23.609759Z","iopub.status.idle":"2025-09-01T12:44:24.425027Z","shell.execute_reply.started":"2025-09-01T12:44:23.609716Z","shell.execute_reply":"2025-09-01T12:44:24.424147Z"}},"outputs":[{"name":"stdout","text":"Classifier:  MLPClassifier(max_iter=1000, random_state=42)\nUsing ESM encoding\nPREDICT PROB\nMCC values for encoding <function ESM at 0x7f5e29067e20> and classifier MLPClassifier\nTraining set 0.7202210730562499\nTest set 0.8177893426774406\nClassifier:  RandomForestClassifier(criterion='entropy', max_depth=9, max_features='log2',\n                       random_state=42)\nUsing ESM encoding\nPREDICT PROB\nMCC values for encoding <function ESM at 0x7f5e29067e20> and classifier RandomForestClassifier\nTraining set 1.0\nTest set 0.7711514889173213\nClassifier:  SVC(C=10, probability=True, random_state=42)\nUsing ESM encoding\nPREDICT PROB\nMCC values for encoding <function ESM at 0x7f5e29067e20> and classifier SVC\nTraining set 0.9813370384863206\nTest set 0.7441107248077677\nClassifier:  LogisticRegression(max_iter=1500, random_state=42)\nUsing ESM encoding\nPREDICT PROB\nMCC values for encoding <function ESM at 0x7f5e29067e20> and classifier LogisticRegression\nTraining set 0.7521823261755706\nTest set 0.7441107248077677\nClassifier:  RandomForestClassifier(criterion='entropy', max_depth=15, max_features='log2',\n                       random_state=42)\nPREDICT PROB\nMCC values for encoding <function BPNC at 0x7f5e284144c0> and classifier RandomForestClassifier\nTraining set 0.9485860385974162\nTest set 0.7441107248077677\nClassifier:  SVC(C=1, probability=True, random_state=42)\nPREDICT PROB\nMCC values for encoding <function CTD at 0x7f5e284155a0> and classifier SVC\nTraining set 0.7055998451932223\nTest set 0.7441107248077677\nClassifier:  AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=5,\n                                                    random_state=42),\n                   random_state=42)\nUsing ESM encoding\nPREDICT PROB\nMCC values for encoding <function ESM at 0x7f5e29067e20> and classifier AdaBoostClassifier\nTraining set 1.0\nTest set 0.721259831406496\nClassifier:  KNeighborsClassifier(metric='manhattan', n_neighbors=7)\nUsing ESM encoding\nPREDICT PROB\nMCC values for encoding <function ESM at 0x7f5e29067e20> and classifier KNeighborsClassifier\nTraining set 0.7056125476364975\nTest set 0.6997023700521369\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"# Join the label column with train_prob_df\ntrain_prob_df = pd.concat([train_prob_df, train['label'].reset_index(drop=True)], axis=1)\n\ntest_prob_df = pd.concat([test_prob_df, test['label'].reset_index(drop=True)], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:44:27.908409Z","iopub.execute_input":"2025-09-01T12:44:27.908693Z","iopub.status.idle":"2025-09-01T12:44:27.916656Z","shell.execute_reply.started":"2025-09-01T12:44:27.908672Z","shell.execute_reply":"2025-09-01T12:44:27.915698Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"train_prob_df.to_csv('/kaggle/working/train_probability_bitter_top_8.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:44:32.349371Z","iopub.execute_input":"2025-09-01T12:44:32.349666Z","iopub.status.idle":"2025-09-01T12:44:32.360434Z","shell.execute_reply.started":"2025-09-01T12:44:32.349642Z","shell.execute_reply":"2025-09-01T12:44:32.359484Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"test_prob_df.to_csv('/kaggle/working/test_probability_bitter_top_8.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:44:35.470369Z","iopub.execute_input":"2025-09-01T12:44:35.470671Z","iopub.status.idle":"2025-09-01T12:44:35.476554Z","shell.execute_reply.started":"2025-09-01T12:44:35.470650Z","shell.execute_reply":"2025-09-01T12:44:35.475605Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"train_prob_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:44:36.421871Z","iopub.execute_input":"2025-09-01T12:44:36.422159Z","iopub.status.idle":"2025-09-01T12:44:36.439483Z","shell.execute_reply.started":"2025-09-01T12:44:36.422139Z","shell.execute_reply":"2025-09-01T12:44:36.438821Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"    ESM_MLP    ESM_RF   ESM_SVM    ESM_LR   BPNC_RF   CTD_SVM       ESM_ADA  \\\n0  0.208869  0.225916  0.120473  0.325637  0.239663  0.201686  3.282021e-07   \n1  0.561328  0.916570  0.890509  0.625433  0.794804  0.650187  9.999997e-01   \n2  0.966768  0.855556  0.976140  0.966847  0.774086  0.936066  1.000000e+00   \n3  0.252922  0.179127  0.120541  0.222454  0.100306  0.540863  4.104141e-06   \n4  0.808304  0.841395  0.890420  0.733661  0.734144  0.965677  9.999998e-01   \n\n    ESM_KNN  label  \n0  0.285714      0  \n1  0.714286      1  \n2  0.857143      1  \n3  0.428571      0  \n4  0.714286      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ESM_MLP</th>\n      <th>ESM_RF</th>\n      <th>ESM_SVM</th>\n      <th>ESM_LR</th>\n      <th>BPNC_RF</th>\n      <th>CTD_SVM</th>\n      <th>ESM_ADA</th>\n      <th>ESM_KNN</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.208869</td>\n      <td>0.225916</td>\n      <td>0.120473</td>\n      <td>0.325637</td>\n      <td>0.239663</td>\n      <td>0.201686</td>\n      <td>3.282021e-07</td>\n      <td>0.285714</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.561328</td>\n      <td>0.916570</td>\n      <td>0.890509</td>\n      <td>0.625433</td>\n      <td>0.794804</td>\n      <td>0.650187</td>\n      <td>9.999997e-01</td>\n      <td>0.714286</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.966768</td>\n      <td>0.855556</td>\n      <td>0.976140</td>\n      <td>0.966847</td>\n      <td>0.774086</td>\n      <td>0.936066</td>\n      <td>1.000000e+00</td>\n      <td>0.857143</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.252922</td>\n      <td>0.179127</td>\n      <td>0.120541</td>\n      <td>0.222454</td>\n      <td>0.100306</td>\n      <td>0.540863</td>\n      <td>4.104141e-06</td>\n      <td>0.428571</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.808304</td>\n      <td>0.841395</td>\n      <td>0.890420</td>\n      <td>0.733661</td>\n      <td>0.734144</td>\n      <td>0.965677</td>\n      <td>9.999998e-01</td>\n      <td>0.714286</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"test_prob_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:44:42.816335Z","iopub.execute_input":"2025-09-01T12:44:42.816638Z","iopub.status.idle":"2025-09-01T12:44:42.828946Z","shell.execute_reply.started":"2025-09-01T12:44:42.816615Z","shell.execute_reply":"2025-09-01T12:44:42.827813Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"    ESM_MLP    ESM_RF   ESM_SVM    ESM_LR   BPNC_RF   CTD_SVM       ESM_ADA  \\\n0  0.889218  0.693474  0.717101  0.891545  0.831900  0.955290  9.999980e-01   \n1  0.139444  0.374270  0.153677  0.403338  0.433875  0.122790  4.213090e-07   \n2  0.082656  0.162166  0.048089  0.086729  0.219467  0.049946  5.067264e-05   \n3  0.027806  0.209480  0.041478  0.046651  0.234724  0.070429  2.934512e-04   \n4  0.003090  0.147000  0.025731  0.012326  0.147277  0.107602  3.981436e-09   \n\n    ESM_KNN  label  \n0  0.714286      1  \n1  0.428571      0  \n2  0.000000      0  \n3  0.000000      0  \n4  0.000000      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ESM_MLP</th>\n      <th>ESM_RF</th>\n      <th>ESM_SVM</th>\n      <th>ESM_LR</th>\n      <th>BPNC_RF</th>\n      <th>CTD_SVM</th>\n      <th>ESM_ADA</th>\n      <th>ESM_KNN</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.889218</td>\n      <td>0.693474</td>\n      <td>0.717101</td>\n      <td>0.891545</td>\n      <td>0.831900</td>\n      <td>0.955290</td>\n      <td>9.999980e-01</td>\n      <td>0.714286</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.139444</td>\n      <td>0.374270</td>\n      <td>0.153677</td>\n      <td>0.403338</td>\n      <td>0.433875</td>\n      <td>0.122790</td>\n      <td>4.213090e-07</td>\n      <td>0.428571</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.082656</td>\n      <td>0.162166</td>\n      <td>0.048089</td>\n      <td>0.086729</td>\n      <td>0.219467</td>\n      <td>0.049946</td>\n      <td>5.067264e-05</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.027806</td>\n      <td>0.209480</td>\n      <td>0.041478</td>\n      <td>0.046651</td>\n      <td>0.234724</td>\n      <td>0.070429</td>\n      <td>2.934512e-04</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.003090</td>\n      <td>0.147000</td>\n      <td>0.025731</td>\n      <td>0.012326</td>\n      <td>0.147277</td>\n      <td>0.107602</td>\n      <td>3.981436e-09</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":55},{"cell_type":"markdown","source":"## Meta Learner","metadata":{}},{"cell_type":"code","source":"def LRegression(X,Y,x,y):\n    #create new a tree model\n    LR=LogisticRegression(random_state=42, max_iter=1500)\n    param_grid = {'penalty':['l2', None]}\n    \n    lr_cv = GridSearchCV(LR, param_grid, scoring='accuracy', cv=KFold(10), n_jobs=4)\n    lr_cv.fit(X, Y)\n    lr=lr_cv.best_estimator_\n    \n    print('\\n Test Results LR\\n')\n    y_p=lr.predict(x)\n    predicted_protability = lr.predict_proba(x)\n    TP, FP, FN, TN = confusion_matrix(y, y_p).ravel()\n    \n    ACC = (TP + TN) / (TP + TN + FP + FN)\n    Sn = TP / (TP + FN)\n    Sp = TN / (TN + FP)\n    BACC = 0.5 * TP / (TP + FN) + 0.5 * TN / (TN + FP)\n    AUC = roc_auc_score(y, predicted_protability[:, 1])\n    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n\n    return lr, ACC, Sn, Sp, BACC, AUC, MCC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:44:45.581645Z","iopub.execute_input":"2025-09-01T12:44:45.582004Z","iopub.status.idle":"2025-09-01T12:44:45.588287Z","shell.execute_reply.started":"2025-09-01T12:44:45.581979Z","shell.execute_reply":"2025-09-01T12:44:45.587439Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# Assuming you have X_train, y_train, X_test, y_test defined\n# Call the LRegression function\nlr, ACC, Sn, Sp, BACC, AUC, MCC = LRegression(train_prob_df.drop('label', axis=1), \n                                          train_prob_df['label'], \n                                          test_prob_df.drop('label', axis=1), \n                                          test_prob_df['label'])\n\n# Print the results\nprint(\"Meta Learner Results:\")\nprint(f\"Accuracy (ACC): {ACC:.4f}\")\nprint(f\"Sensitivity (Sn): {Sn:.4f}\")\nprint(f\"Specificity (Sp): {Sp:.4f}\")\nprint(f\"Balanced Accuracy (BACC): {BACC:.4f}\")\nprint(f\"Area Under Curve (AUC): {AUC:.4f}\")\nprint(f\"Matthews Correlation Coefficient (MCC): {MCC:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T23:55:25.090046Z","iopub.execute_input":"2025-03-27T23:55:25.090439Z","iopub.status.idle":"2025-03-27T23:55:26.981513Z","shell.execute_reply.started":"2025-03-27T23:55:25.090413Z","shell.execute_reply":"2025-03-27T23:55:26.980330Z"}},"outputs":[{"name":"stdout","text":"\n Test Results LR\n\nMeta Learner Results:\nAccuracy (ACC): 0.9531\nSensitivity (Sn): 0.9531\nSpecificity (Sp): 0.9531\nBalanced Accuracy (BACC): 0.9531\nArea Under Curve (AUC): 0.9836\nMatthews Correlation Coefficient (MCC): 0.9062\n","output_type":"stream"}],"execution_count":104},{"cell_type":"code","source":"import json\n\n# Convert the model dictionary to a JSON-serializable format\nserializable_model = {key: (str(value[0]), value[1]) for key, value in models.items()}\n\n# Save to a JSON file\nwith open(\"model_results.json\", \"w\") as f:\n    json.dump(serializable_model, f, indent=4)\n\nprint(\"Model results saved to model_results.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:45:11.916387Z","iopub.execute_input":"2025-09-01T12:45:11.916828Z","iopub.status.idle":"2025-09-01T12:45:11.937795Z","shell.execute_reply.started":"2025-09-01T12:45:11.916793Z","shell.execute_reply":"2025-09-01T12:45:11.936932Z"}},"outputs":[{"name":"stdout","text":"Model results saved to model_results.json\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"# Convert the model dictionary to a JSON-serializable format\nserializable_model = {key: (str(value[0]), value[1]) for key, value in top_models_dict.items()}\n\n# Save to a JSON file\nwith open(\"top_8_model_results.json\", \"w\") as f:\n    json.dump(serializable_model, f, indent=4)\n\nprint(\"Model results saved to model_results.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:45:14.522041Z","iopub.execute_input":"2025-09-01T12:45:14.522341Z","iopub.status.idle":"2025-09-01T12:45:14.530379Z","shell.execute_reply.started":"2025-09-01T12:45:14.522319Z","shell.execute_reply":"2025-09-01T12:45:14.529593Z"}},"outputs":[{"name":"stdout","text":"Model results saved to model_results.json\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"import joblib\nimport json\nimport os\n\n# Directory to save models\nsave_dir = \"saved_models\"\nos.makedirs(save_dir, exist_ok=True)\n\n# Dictionary to store MCC scores\nmcc_scores = {}\n\nfor model_name, (model, mcc) in top_models_dict.items():\n    # Save model\n    model_path = os.path.join(save_dir, f\"{model_name}.pkl\")\n    joblib.dump(model, model_path)\n    \n    # Store MCC score\n    mcc_scores[model_name] = mcc\n\n# Save MCC scores to a JSON file\nmcc_path = os.path.join(save_dir, \"mcc_scores.json\")\nwith open(mcc_path, \"w\") as f:\n    json.dump(mcc_scores, f, indent=4)\n\nprint(f\"Models and MCC scores saved in '{save_dir}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T12:45:16.061861Z","iopub.execute_input":"2025-09-01T12:45:16.062151Z","iopub.status.idle":"2025-09-01T12:45:16.171005Z","shell.execute_reply.started":"2025-09-01T12:45:16.062132Z","shell.execute_reply":"2025-09-01T12:45:16.170052Z"}},"outputs":[{"name":"stdout","text":"Models and MCC scores saved in 'saved_models'\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}